{
 "metadata": {
  "name": "",
  "signature": "sha256:45bbcaeb212b57501cef8f9a84e38f638c0b44582abc13c1c35452389f19937f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Model checking: Training, Testing and Validation\n",
      "\n",
      "### 4th November 2014 Neil D. Lawrence"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# download the software\n",
      "import urllib\n",
      "\n",
      "urllib.urlretrieve('https://github.com/sods/ods/archive/master.zip', 'master.zip')\n",
      "\n",
      "# unzip the software\n",
      "import zipfile\n",
      "zip = zipfile.ZipFile('./master.zip', 'r')\n",
      "for name in zip.namelist():\n",
      "    zip.extract(name, '.')\n",
      "\n",
      "# add the module location to the python path.    \n",
      "import sys\n",
      "sys.path.append(\"./ods-master/\") "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will review the different methods of model selection on the Olympics marathon data. Firstly we import the olympics data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pods\n",
      "data = pods.datasets.olympic_marathon_men()\n",
      "x = data['X']\n",
      "y = data['Y']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can plot them to check that they've loaded in correctly.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pylab as plt\n",
      "plt.plot(x, y, 'rx')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[<matplotlib.lines.Line2D at 0x10db65ed0>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEn9JREFUeJzt3X+MHPV5x/H3YVMcN44uMcREBfdcIxXTpk0qMBWGZFWV\nQGKbIMVtAoXQVpHcpKWIELdNjORLlQtVISYopMINjVRa4lQFhQSOpqIiS8uFHwXMj9SUlvNZRSoG\nGrwoaSICZfvHd9Y3t7d3N+Od3Z3Z7/slrXZ3ZnbvWXvnMzPPzM6AJEmSJEmSJEmSJEmSJEmS+ugg\n8CSwD3i4w/ga8Eoyfh9wdb8KkyQVawZ42yLja8C3+lOKJOloHJNj2pEux0uSBihr4DeBe4E7gAsW\nGH8W8DiwG1hfSHWSpL57R3K/AXgWOLFt/CpgJXAs8DHgrv6VJknK4mjaMLuBp4GvLPKeh4C1wKut\ngevXr29OT08fxZ+TpKhNA6cU8UZZWjorCWvwACcA5wHfbptmDbMLj62EI3peTU8wPT1Ns9ms7G3X\nrl0DryHW+qtcu/UP/lb1+imwRb48wzRrgG8kj78PfAF4DtieDNsDbAM+DrxOCPuriipQklSMLIE/\nA7yrw/A9qcdfTm6SpJLKc1hm1Gq12qBL6EqV669y7WD9g1b1+ovUz2Pnm0k/SpKU0cjICBSU1a7h\nS1IkDHxJioSBL0mRMPAlKRIGviRFwsCXpEgY+JIUCQNfkiJh4EtSJAx8SYqEgS9JkTDwuzU5CY3G\n3GGNRhguSSVi4Hdr0ybYuXM29BuN8HzTpsHWJUltPFtmEVohv2MHXHstTEzA6Oigq5I0BIo8W6aB\nX5SDB2HdOpiZgbGxQVcjaUh4euSyaTTCmv3MTLhv7+lLUgkY+N1qtXMmJsKa/cTE3J6+JJWELZ1u\nTU6GHbTpnn2jAVNTsHnz4OqSNBTs4UtSJOzhS5JyM/AlKRIGviRFwsCXpEgY+JIUCQNfkiJh4EtS\nJLIG/kHgSWAf8PAC01wDHAAeBU7tujJJUqGWZ5yuCdSAlxcYvxE4BzgdOA+4DtjSbXGSpOLkaeks\n9kuvM4HbCAuEvcCGboqSJBUva+A3gXuBO4ALOozfCOxPPX8JWN9daZKkImVt6WwCniesud9J6OMf\nSo0fYf4WgCfOkaQSyRr4zyf3TwPfArYCX0mNfwg4DfjH5PkJhB24c4yPjx95XKvVqNVquYqVpGFX\nr9ep1+s9ee8sZ2BbCSwDfkAI8jpwPvBcapqNwG7gg4Sdthczf6etZ8uUpJyKPFtmljX8NcA3ksff\nB75ACPvtybA9hBbP/cAjhB23lxRRnCSpOJ4PX5JKzPPhS5JyM/AlKRIGviRFwsCXpEgY+JIUCQNf\nkiJh4EtSJAx8SYqEgS9JkTDwJSkSBr4kRcLAl6RIGPiSFAkDX5IiYeBLUiQMfEmKhIEvSZEw8CUp\nEga+JEXCwJekSBj4khQJA1+SImHgS1IkDHxJioSBL0mRMPAlKRIGviRFwsCXpEgY+JIUiayBvwzY\nB9zZYVwNeCUZvw+4upDKJEmFWp5xuiuA/cCqBcbfB1xQSEWSpJ7IsoZ/EvAB4GZgZIFpFhouSSqJ\nLIF/PbADeGOB8U3gLOBxYDewvpjSemhyEhqNucMajTBckobUUi2dLcCLhN58bYFpHgNOBl4DLgNu\nSF43z/j4+JHHtVqNWm2ht+yxTZtg506YmIDR0RD2redpk5Nh2tHR2WGNBkxNwebN/a1ZUhTq9Tr1\ner0n771UK+bzwKXA68AK4C3A7cBHF3m/Q8Ba4NW2cc1ms3n0lRatFfI7dsC1186Gf6dpOi0Y2qeV\npB4YGRmBgtrmed7kvcCngK1tw9cQtgKahB23lwPndnh9uQIf4OBBWLcOZmZgbKzzNFkWDJLUI0UG\nft7j8FuJvT25AWwDniL08LcBVxVRWM81GiHAZ2bCfXtPv2V0NIT9unXh3rCXVFH9PLqmPGv4eVo1\nruFLGqBBtXS6VZ7Az7oz1h6+pAEz8PvFo3QkDZiBL0mRGOROW0lSRRn4khQJA1+SImHgS1IkDHxJ\nioSBL0mRMPAlKRIGviRFwsCXpEgY+JIUCQNfkiJh4EtSJAx8SYqEgS9JkTDwJSkSBn6/TE7Ov25u\noxGGS1IfGPj9smlTuDxiK/Rbl0vctGmwdUmKhle86icviC4pJy9xWGUHD8K6dTAzA2Njg65GUsl5\nicOqajTCmv3MTLhv7+lLUg8Z+P3SaudMTIQ1+4mJuT19SeoxWzr9MjkZdtCme/aNBkxNwebNg6tL\nUqnZw5ekSNjDlyTlZuBLUiSyBv4yYB9w5wLjrwEOAI8CpxZQlySpYFkD/wpgP9CpCb8ROAc4Hbgu\nuUmSSiZL4J8EfAC4mc47Ds4EbgNeBvYCGwqrTpJUmCyBfz2wA3hjgfEbCWv/LS8B67usS5JUsOVL\njN8CvEjo39cWmGaE+Wv+HY+/HB8fP/K4VqtRqy30lpIUp3q9Tr1e78l7L3Vs5+eBS4HXgRXAW4Db\ngY+mprmcsOC4Pnk+Tec1fI/Dl6Sc+nkc/meAk4F1wEeAe5kb9gAPAR8CVgMXA08XUZgkqVhLtXTa\ntVbRtyf3e4CHgfuBRwg7bi8ppjRJUpE8tULZeM4dSSmeWmGYeWUsST3iGn4ZeWUsSQnPlhkDr4wl\nCVs6w88rY0nqAQO/bLwylqQeMfDLZmpqbs9+dDQ8n5rqzd+bnJy/MGk0wnBJQ8UefuzSWxSjo/Of\nSxood9qqWB4VJJWWga/ieVSQVEoepaNieVSQFAUDP3YeFSRFw5ZO7Dx3j1Rq9vAlKRL28CVJuRn4\nkhQJA1+SImHgS1IkDHzFwXMGSQa+IuGVxCQPy1REPGeQKsjj8NV/w/IDLc8ZpIrxOHz13zC0RDxn\nkCJn4Cub1oVYdu4Ma8mdzplf5h2jnjNIsqWjnBZriZT5YirD0pJSdGzpKJui17iXaolk2QoYlM2b\n59cxOmrYKyqu4Q+zIte487yXO0alwriGr2yKXOPOenF1d4xKpeUafgz6tcaddSvAfrqUWb/X8FcA\nDwGPAw8CV3aYpga8AuxLblcXUZwK0M817qxbAcNwiKdUQVmXGiuBHwHHAY8CFwLPpsbXgE8CFyzy\nHq7h91uZj5rxV69SJoP8pe1qYAo4F3guNbwGXAVsXeS1Bn6/lb114s5daUmD2Gl7DPAE8AJwI3PD\nHqAJnEVo++wG1hdRnLpU5kMR3bkr9d3yjNO9AfwyMAbcTVjL35ca/xhwMvAacBlwA7Cl/U3Gx8eP\nPK7VatRqtfwVq/raW0utI4ls60jU63Xq9XpP3vtoNhOuI/Tvb1rkPQ8Ba4FXU8Nt6Sgoe6tJKpF+\nt3SOB1pz5mrgfcA326ZZkypoK/Akc8NemlXmVlMWZT5nkLSILIH/DuBeQg//a4Q1/OeB7ckNYBvw\nFKGHv42wA1caTh5Wqoryh1fS0fCwUvWJF0CRysDDStUHnktH6oU8vXkPK1UFGfhSS9bevBdTUUXZ\n0pHSsvTmPaxUfWQPX+ole/MqEXv4Uq+UsTfvcf8qiIEvtZS1N+9x/yqILR2ppcy9eY/7j5Y9fClG\n7luIkj18KTZl3LegyjHwpbIr674FVY4tHansyrxvQT1nD1+SImEPX5KUm4Ev9YI/llIJGfhSL/hj\nKZWQPXypV/yxlArgTlupKvyxlLrkTlupCvyxVD7u9+g5A1/qhUH8WKrqgZllv0fVP2NEmlI07rqr\n2Tx8eO6ww4fD8KOZLovDh5vNT3xi9v3an1dBq+aZmc61D8NnzAmoZC980P9uUvkUHWBLBWYVzMw0\nmxDuOxmGz5gDBr40RIoOsKUCM4sitzzyyPpvUcRnbDYH9zlzwMCXhkxRAVbUwqPILY+soZr1b2b5\njEX/zQHCwJeGSL9DOm8YlqmuvAuFLEFe8hYRBr40JMq8Jt1sLr3l0e+FR54WTJ6/WdQWVg9g4EtD\nosy98jzTFLHw6IUsf9M1/J4Y9L+bpLTFwrDolsggQrXoBdZSerTwpo+BvwJ4CHgceBC4coHprgEO\nAI8Cpy4wTVcfWlKBlgrDvOFV1MKjKEXvzyjyb+ZEn9fwVyb3xwHfA05pG78RuB94G3ARcNcC79PV\nh5ZUkH4f+z+ItlWZW2U5UWDg5zkhz2pgCjgXeC41/HJgGfDF5Pk0sL7D65PaJQ1UkZdMTJ9CYnR0\n/vNhkPffq+AT5vX75GnHAE8ALwA3MjfsIazh7089f4nOgS+pDDZvnh/Go6NHd33cqam54T46Gp5P\nTXVfZ1nkubbBEJ0wb4wQ7O9uG/63wHmp5w8CP9fh9V1v2kjSQPR7B3AKA2rpAFwHPAvclBp2ObAc\nuD55vmBLZ9euXUee1Go1arVazj8vSQOyVKumoFZZvV6nXq8fef7Zz34W+nQBlOOB14EGoYf/HcLa\n/POpaTYCu4EPJuMuBrZ0eK9kYSVJFTPAq5f184pX7wT+mrBT9hBwK3ALsD0Zvye5/zPgw8DLwCXA\n0x3ey8CXVD0D3jHtJQ4lqV+KPKrpKBj4khQJr2krScrNwJekSBj4khQJA1+SImHgS1IkDHxJioSB\nL0mRMPAlKRIGviRFwsCXpEgY+JIUCQNfkiJh4EtSJAx8SYqEgS9JkTDwJSkSBr4kRcLAl6RIGPiS\nFAkDX5IiYeBLUiQMfEmKhIEvSZEw8CUpEga+JEXCwJekSBj4khSJLIF/MvAd4N+AOnBxh2lqwCvA\nvuR2dTHlSZKKkiXwXwOuBH4B2AZ8DljVYbr7gHcnt88VVWBZ1Ov1QZfQlSrXX+XawfoHrer1FylL\n4B8CHk8e/w9hTf/0DtONFFVUGVX9S1Pl+qtcO1j/oFW9/iLl7eGfQljTf7hteBM4i7Bg2A2s7740\nSVKR8gT+KuDvCO2d/20b9xih138GsB+4oZDqJEmFydqGORaYBO4GvpjhPQ8Ba4FXU8OfxTV/Scpr\nmtBd6YsR4BZCq2Yha5hdeFwA3NProiRJxTsbeIPQn28ddvl+YHtyA/h94HvJNLcAv9T/MiVJkiR1\n5avAC8BTqWGnAXcR1vTvBDYkw0cIO3IfBb4LfCz1mg2Enb4HgIneljxHp/p/HriVsOP568CbUuP+\nEPjPZNzZqeFVqP9c4BHgSeAOYGPqNVWov2Ut8EPgqtSwqtR/CuEHjM8Q/h+OS4YPov48tZdx3l3o\nx6CrgG8C/0X4nr859Zoyzb956y/F/HsO4UdW6S/N14HfTB5fBOxNHp9PWBBA+FAHgdHk+d3Ah4HV\nwP10Psa/FzrV/zXgN5LHfwJcnjx+O/DvhMB5L+EfuKUK9b8LODF5/B7gn1OvqUL9LbcRjhRLB35V\n6r+f8MNFgLcye4TcIOrPU3sZ590TCd9pgOMJYbcK+CPgS4SF6Y3Ap5Jpyjb/5q2/NPPvGHO/NHuA\njxO+zH8A/EUy/CzgXmAlYek2A/xUMm469fpPEvYH9MsYc+v/b2BF8vg0wgIMYCtzj07ax+zStwr1\np40ALwPLkudVqf9C4M+BXcwN/CrU/3bgXxZ4j0HVP0a22ss676bdCfwaYYWgFaS/Avx98ris82/L\nUvWndTX/Fn3ytB3AFcDh5A//cTL8u8CDhM3IA8DvAT8hbOa+mHr9fuBXC64pj3uA3yYsYS8jfNkB\nzgSeTk33TDKsKvWnXQQ8APwf1an/zYS1n/G26atS//sI88Q9wD8R/g+gXPUvVHvZ5930j0HPIKzJ\nk9y3Wh9lnn+z1J/W1fxbdOB/lbBJshq4CfirZPgWwodZS/hwNyfTtP8OYNCnZ9gF/CLhC74M+PEi\n0zY7DCt7/e8E/pSw9QXV+fcfB64HfsTcGqtS/wrCjLgduAT4NPCzlKv+hWov87yb/jHoD3PWUIb5\nN2/9Xc+/y3MWuJSzgUuB1wlh/+lk+HuA2wlrOYcJaw1nAN8mHMPfchrhCzcoB5n9x3w/s5uuDwG/\nnpruVOBfgR9QjfoBTiJsMl5K2CyHsBOrCvVvBD5EaOmMEg4T/jGhZViF+h8gnFzwQPL8H4DzgL+k\nPPUfpHPtZZ13j03q+hvCjk4I8+QGQstmQ/Icyjn/5qkfSjL/jjG3D7iXsAMB4LcIHwbCl/sOwpfo\neELfqdVDuxv4SDK8nzt+YH79JyT3P0Poq21Onq9hdqdPjfk7fcpe/yjwBKEP3q4K9aftIvQqW6pQ\n/zGEIzLeCvw0YfO99cvJQdU/RrbayzjvLvRj0NZOzzcBX2Z2p2fZ5t+89Zdi/t1L2NHzE+A54HcI\nm3x7k+JuJSxJIWwiThCWWPcRNmtbTiP8B8wA1/Sq2A7a6/9dwqFbzwD/AXymbforCKeH2E84yqGl\nCvVfTdhk3Je6HZ+Mq0L9ae2BX5X6LySE/gPMrknDYOrPU3sZ591OPwY9n8UPyyzT/Ju3/jLOv5Ik\nSZIkSZIkSZIkSZIkSZIkSZI0HP4fImpkzO+i+yoAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10dba20d0>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Linear Model Fit\n",
      "\n",
      "The first thing we'll do is fit a standard linear model to the data. We recall from previous lectures and the lab classes that to do this we need to solve the system\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Assignment Question 1\n",
      "\n",
      "Construct a basis set $\\boldsymbol{\\Phi}$ of the form\n",
      "$$\n",
      "\\boldsymbol{\\Phi} = \\begin{bmatrix} \\mathbf{1} & \\mathbf{x}\\end{bmatrix}\n",
      "$$\n",
      "from the olympics data and solve the system\n",
      "$$\n",
      "\\boldsymbol{\\Phi}^\\top \\boldsymbol{\\Phi} \\mathbf{w} = \\boldsymbol{\\Phi}^\\top \\mathbf{y}\n",
      "$$\n",
      "to recover the parameters of the linear model. Plot the linear fit to the data between 1880 and 2020.\n",
      "\n",
      "*15 marks*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def linear(x):\n",
      "    return np.hstack((np.ones_like(x), x))\n",
      "\n",
      "import numpy as np\n",
      "Phi = linear(x)\n",
      "PhiTPhi = np.dot(Phi.T, Phi)\n",
      "PhiTy = np.dot(Phi.T, y)\n",
      "# solve the system PhiTPhi w = PhiTy\n",
      "w = np.linalg.solve(PhiTPhi, PhiTy)\n",
      "\n",
      "x_test = np.linspace(1880, 2020, 140)[:, None]\n",
      "Phi_test = kinear(x_test)\n",
      "f_test = np.dot(Phi_test.T, w)\n",
      "fix, ax = plt.subplots()\n",
      "plt.plot(x_test, f_test, 'r-')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(np.linspace(1, 2, 10).shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Training Error\n",
      "\n",
      "The first thing we'll do is plot the training error for the polynomial fit. To do this let's set up some parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "num_data = x.shape[0]\n",
      "num_pred_data = 100 # how many points to use for plotting predictions\n",
      "x_pred = np.linspace(1890, 2016, num_pred_data)[:, None] # input locations for predictions\n",
      "order = 4 # The polynomial order to use."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "now let's build the basis matrices.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build the basis set\n",
      "Phi = np.zeros((num_data, order+1))\n",
      "Phi_pred = np.zeros((num_pred_data, order+1))\n",
      "for i in range(0, order+1):\n",
      "    Phi[:, i:i+1] = x**i\n",
      "    Phi_pred[:, i:i+1] = x_pred**i\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "now we can solve for the regression weights and make predictions both for the training data points, and the test data points. That involves solving the linear system given by\n",
      "\n",
      "$$\\basisMatrix^\\top \\basisMatrix \\mappingVector^* = \\basisMatrix^\\top \\dataVector$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# solve the linear system\n",
      "w_star = np.linalg.solve(np.dot(Phi.T, Phi), np.dot(Phi.T, y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and using the resulting vector to make predictions at the training points and test points,\n",
      "\n",
      "$$\\mathbf{f} = \\basisMatrix \\mappingVector.$$\n",
      "\n",
      "To implement this in practice we need to use basis matrices for both the predictions and the training points."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# predict at training and test points\n",
      "f = np.dot(Phi, w_star)\n",
      "f_pred = np.dot(Phi_pred, w_star)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These can be used to compute the objective functions\n",
      "\n",
      "$$E(\\mappingVector) =  \\frac{\\numData}{2} \\log \\dataStd^2 + \\frac{1}{2\\dataStd^2} \\sum_{i=1}^\\numData \\left(\\dataScalar_i - \\mappingVector^\\top \\phi(\\inputVector_i)\\right)^2 \\\\\\\n",
      "E(\\mappingVector) = \\frac{\\numData}{2} \\log \\dataStd^2 + \\frac{1}{2\\dataStd^2} \\sum_{i=1}^\\numData \\left(\\dataScalar_i - \\mappingFunctionScalar_i\\right)^2$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute the sum of squares term\n",
      "sum_squares = ((y-f)**2).sum()\n",
      "# fit the noise variance\n",
      "sigma2 = sum_squares/num_data\n",
      "objective = 0.5*(num_data*np.log(sigma2) + sum_squares/sigma2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have the fit and the objective function, let's plot the fit and the objective."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print the error and plot the predictions\n",
      "print(\"The objective is: %2.4f\"%objective)\n",
      "plt.plot(x_pred, f_pred)\n",
      "plt.plot(x, y, 'rx')\n",
      "ax = plt.gca()\n",
      "ax.set_title('Predictions for Order 5')\n",
      "ax.set_xlabel('year')\n",
      "ax.set_ylabel('pace (min/km)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now use the loop structure below to compute the error for different model orders.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import the time model to allow python to pause.\n",
      "import time\n",
      "# import the IPython display module to clear the output.\n",
      "from IPython.display import clear_output\n",
      "\n",
      "error_list = []\n",
      "max_order = 6\n",
      "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
      "for order in range(0, max_order+1):\n",
      "    # 1. build the basis set\n",
      "    Phi = np.zeros((num_data, order+1))\n",
      "    Phi_pred = np.zeros((num_pred_data, order+1))\n",
      "    for i in range(0, order+1):\n",
      "        Phi[:, i:i+1] = x**i\n",
      "        Phi_pred[:, i:i+1] = x_pred**i\n",
      "    # 2. solve the linear system\n",
      "    # 3. make predictions at training and test points\n",
      "    # 4. compute the error and append it to a list.\n",
      "    # 5. plot the predictions\n",
      "    axes[0].clear()\n",
      "    axes[1].clear()    \n",
      "    axes[0].plot(x_pred, f_pred)\n",
      "    axes[0].plot(x, y, 'rx')\n",
      "    axes[0].set_ylim((2.5, 5.5))\n",
      "    axes[0].set_title('Predictions for Order ' + str(order) + ' model.')\n",
      "    axes[1].plot(np.arange(0, order+1), np.asarray(error_list))\n",
      "    axes[1].set_xlim((0, max_order))\n",
      "    axes[1].set_ylim((-30, 0))\n",
      "    axes[1].set_title('Training Error')\n",
      "    display(fig)\n",
      "    time.sleep(1)\n",
      "    clear_output()\n",
      "    \n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hold Out Validation\n",
      "\n",
      "The error we computed above is the training error. It doesn't assess the model's generalization ability, it only assesses how well it's performing on the given training data. In hold out validation, we keep back some of the training data for assessing generalization performance. In the case of time series prediction, it often makes sense to hold out the last few data points, in particular, when we are interested in *extrapolation*, i.e. predicting into the future given the past. To perform hold out validation, we first remove the hold out set. If we were interested in interpolation, we would hold out some random points. Here, because we are interested in extrapolation, we will hold out all points since 1980. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a training set\n",
      "x_train = x\n",
      "y_train = y\n",
      "indices_hold_out = np.nonzero(x>1980)\n",
      "x_train = np.delete(x, indices_hold_out)\n",
      "y_train = np.delete(y, indices_hold_out)\n",
      "\n",
      "# Create a hold out set\n",
      "x_hold_out = x[indices_hold_out]\n",
      "y_hold_out = y[indices_hold_out]\n",
      "\n",
      "# Now use the training set and hold out set to compute the errors like above.\n",
      "\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now you have the training and hold out data, you should be able to use the code above to evaluate the model on the hold out data. Do this in the code block below.\n",
      "\n",
      "## Leave One Out Validation\n",
      "\n",
      "In leave one out validation, you take out one data point at a time and compute the error. Perform leave one out validation on this data set. Test polynomial basis from 0th order to 6th order.\n",
      "\n",
      "## $k$-fold Cross Validation\n",
      "\n",
      "Repeat this test again for 5-fold cross validation. Here you need to split the data into 5 parts. Then use each part as a hold out validation set (in turn), whilst training on the four remaining parts. This is known as five fold cross validation. \n",
      "\n",
      "\n",
      "Do the different forms of validation select different models?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}